import gymnasium as gym
import numpy as np
import pygad
import time
import matplotlib.pyplot as plt

# Utw贸rz rodowisko LunarLander bez wizualizacji dla treningu
env = gym.make("LunarLander-v3")
print(f"rodowisko: {env.spec.id}")
print(f"Przestrze obserwacji: {env.observation_space}")
print(f"Przestrze akcji: {env.action_space}")

# Parametry chromosomu dla LunarLander
CHROMOSOME_LENGTH = 500  # Maksymalna dugo epizodu
POPULATION_SIZE = 50     # Populacja chromosom贸w
NUM_GENERATIONS = 100    # Liczba generacji

def fitness_function(ga_instance, solution, solution_idx):
    """
    Funkcja fitness dla algorytmu genetycznego w LunarLander.
    
    CHROMOSOM: Lista liczb cakowitych [0,1,2,3] reprezentujcych akcje:
    - 0: NIC (brak akcji)
    - 1: LEWY silnik
    - 2: GWNY silnik (do g贸ry)
    - 3: PRAWY silnik
    
    FUNKCJA FITNESS:
    1. Symuluje epizod LunarLander wykonujc akcje z chromosomu
    2. Zbiera nagrody rodowiska kt贸re uwzgldniaj:
       - Pozycj wzgldem ldowiska
       - Prdko pionow i poziom
       - Kt i prdko ktow ldownika
       - Kontakt z ziemi (nogi dotykajce powierzchni)
       - Zu偶ycie paliwa
    3. Dodatkowe bonusy/kary:
       - Sukces ldowania: +100 punkt贸w
       - Katastrofa: -100 punkt贸w
       - Bonus za dugie utrzymanie si w powietrzu
    """
    observation, info = env.reset(seed=42)
    total_reward = 0
    steps_taken = 0
    
    for action in solution:
        observation, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        steps_taken += 1
        
        # Sprawd藕 czy epizod si zakoczy
        if terminated or truncated:
            # Analiza przyczyny zakoczenia na podstawie nagrody
            if reward >= 100:  # Sukces ldowania
                total_reward += 100  # Dodatkowy bonus za sukces
                print(f"Udane ldowanie! Kroki: {steps_taken}, Nagroda: {total_reward:.2f}")
            elif reward <= -100:  # Katastrofa
                total_reward -= 100  # Dodatkowa kara za katastrof
            break
    
    # Bonus za dugo epizodu (du偶sze loty = lepsze sterowanie)
    survival_bonus = steps_taken / CHROMOSOME_LENGTH * 10
    total_reward += survival_bonus
    
    return total_reward

def on_generation(ga_instance):
    """Callback wywoywany po ka偶dej generacji"""
    best_fitness = ga_instance.best_solution()[1]
    avg_fitness = np.mean(ga_instance.last_generation_fitness)
    print(f"Generacja {ga_instance.generations_completed}: "
          f"Najlepszy={best_fitness:.2f}, redni={avg_fitness:.2f}")

# Konfiguracja algorytmu genetycznego
ga_instance = pygad.GA(
    num_generations=NUM_GENERATIONS,
    num_parents_mating=15,
    fitness_func=fitness_function,
    sol_per_pop=POPULATION_SIZE,
    num_genes=CHROMOSOME_LENGTH,
    gene_type=int,
    gene_space=[0, 1, 2, 3],  # Mo偶liwe akcje w LunarLander
    mutation_type="random",
    mutation_percent_genes=20,  # Wy偶sza mutacja dla eksploracji
    crossover_type="two_points",  # Krzy偶owanie dwupunktowe
    parent_selection_type="rank",  # Selekcja rankingowa
    on_generation=on_generation,
    random_seed=42
)

# Uruchom algorytm genetyczny
print("Rozpoczynam trening algorytmu genetycznego dla LunarLander...")
start_time = time.time()
ga_instance.run()
end_time = time.time()

# Poka偶 najlepsze rozwizanie
best_solution, best_fitness, _ = ga_instance.best_solution()
print(f"\nTrening zakoczony w {end_time - start_time:.2f} sekund")
print(f"Najlepsze rozwizanie:")
print(f"Warto funkcji fitness: {best_fitness:.2f}")

env.close()

# Wizualna demonstracja najlepszego rozwizania z render_mode="human"
print("\n" + "="*60)
print("WIZUALNA DEMONSTRACJA NAJLEPSZEGO ROZWIZANIA")
print("="*60)

action_names = {0: "NIC", 1: "LEWY", 2: "GWNY", 3: "PRAWY"}

# Utw贸rz nowe rodowisko z trybem wizualnym
visual_env = gym.make("LunarLander-v3", render_mode="human")

observation, info = visual_env.reset(seed=42)
total_reward = 0
step_count = 0

print("Nacinij Enter, aby rozpocz wizualn demonstracj ldowania...")
input()

for action in best_solution:
    observation, reward, terminated, truncated, info = visual_env.step(action)
    total_reward += reward
    step_count += 1
    
    # Wywietl informacje co 50 krok贸w
    if step_count % 50 == 0:
        print(f"\nKrok {step_count}: Akcja={action_names[action]}")
        print(f"Pozycja: ({observation[0]:.2f}, {observation[1]:.2f})")
        print(f"Prdko: ({observation[2]:.2f}, {observation[3]:.2f})")
        print(f"Kt: {observation[4]:.2f}, Prdko ktowa: {observation[5]:.2f}")
        print(f"Nagroda czna: {total_reward:.2f}")
    
    # Kr贸tka pauza dla lepszej obserwacji
    time.sleep(0.02)
    
    if terminated or truncated:
        if reward >= 100:
            print(f"\n SUKCES! Udane ldowanie po {step_count} krokach!")
            print(f"Kocowa nagroda za ldowanie: {reward:.2f}")
        elif reward <= -100:
            print(f"\n KATASTROFA! Ldownik rozbi si po {step_count} krokach!")
        else:
            print(f"\n憋 Epizod zakoczony po {step_count} krokach (timeout).")
        break

print(f"\nKocowa suma nagr贸d: {total_reward:.2f}")
print("Nacinij Enter, aby zamkn okno gry...")
input()
visual_env.close()

# Poka偶 wykres postpu fitness
ga_instance.plot_fitness()
plt.title("Postp algorytmu genetycznego w LunarLander")
plt.xlabel("Generacja")
plt.ylabel("Fitness")
plt.show()